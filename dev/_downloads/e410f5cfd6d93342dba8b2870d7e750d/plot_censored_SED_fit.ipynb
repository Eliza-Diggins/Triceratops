{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Fit Censored Radio Photometry to a BPL\n\nIn this example, we'll do consider the relatively simple task of fitting a single epoch of\ncensored radio photometry data using a broken power-law (BPL) model. This is an excellent\nexample of the robust data handling and likelihood construction of the Triceratops library.\n\nWe'll use the :class:`~models.emission.synchrotron.Synchrotron_SSA_SBPL_SED` model to generate some synthetic\ndata with a fixed noise threshold and then we'll invert that data to recover the original parameters using MCMC.\nThis will take us through the basic steps of generating the model, defining the dataset, setting up the likelihood,\nand running the inference with correct priors.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nfrom astropy import units as u"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\nFirst, we need to import the necessary libraries\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from triceratops.models.emission.synchrotron import Synchrotron_SSA_SBPL_SED"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, the :class:`~models.emission.synchrotron.Synchrotron_SSA_SBPL_SED` model produces a synchrotron SED\nwith the form:\n\n\\begin{align}F_{\\nu} = F_{\\nu,0}\n   \\left[\n       \\left( \\frac{\\nu}{\\nu_{\\rm break}} \\right)^{\\alpha_{\\rm thick}/s}\n       +\n       \\left( \\frac{\\nu}{\\nu_{\\rm break}} \\right)^{\\alpha_{\\rm thin}/s}\n   \\right]^s,\\end{align}\n\nwhere $F_{\\nu,0}$ is the normalization at the break frequency\n$\\nu_{\\rm break}$. The spectral indices are tied to the electron energy\ndistribution power-law index $p$ via\n\n\\begin{align}\\alpha_{\\rm thick} = \\frac{5}{2},\n   \\qquad\n   \\alpha_{\\rm thin} = -\\frac{p - 1}{2}.\\end{align}\n\nThis choice reproduces the canonical optically thick and optically thin synchrotron\nspectral slopes expected for a homogeneous emitting region with a power-law electron\npopulation.\n\nIn order to produce the synthetic data, we'll first define a set of model parameters and then forward model their\nSED with a Gaussian noise with a standard deviation proportional to the flux density.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Generate the forward model object.\nsed_model = Synchrotron_SSA_SBPL_SED()\n\n# Create a parameter dictionary with our preferred true values.\ntrue_params = {\"norm\": 5.0 * u.mJy, \"nu_break\": 4.0 * u.GHz, \"p\": 3.0, \"s\": -1.0}\n\n# Define the noise level as a fraction of the flux density.\nnoise_fraction = 0.3  # 5% noise\n\n# Generate the frequencies to use for the synthetic data.\nfrequencies = u.Quantity([0.1, 0.5, 1.0, 3.0, 5.0, 7.0, 10.0, 15.0, 20.0, 30.0], u.GHz)\n\n# Create the fake flux limit\nflux_floor = 0.5 * u.mJy\n\n# Generate the synthetic flux densities with noise.\nsynthetic_flux = sed_model.forward_model({\"frequency\": frequencies}, true_params)[\"flux_density\"]\nsynthetic_flux += (\n    np.random.normal(size=synthetic_flux.shape, scale=noise_fraction * synthetic_flux.to_value(\"mJy\")) * u.mJy\n)\n\n# Apply the flux floor to create censored data\nsynthetic_flux = np.where(synthetic_flux < flux_floor, flux_floor, synthetic_flux)\n\n# create masks for the censored data\ncensored_mask = synthetic_flux <= flux_floor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's go ahead and look at the plot of the true model and the synthetic data points.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n\n# Create a figure and axis for the plot.\nfig, ax = plt.subplots(figsize=(10, 6))\n\n# Plot the true model.\nfreqs_plot = np.logspace(8, 11, 100) * u.Hz\ntrue_flux_plot = sed_model.forward_model({\"frequency\": freqs_plot}, true_params)[\"flux_density\"]\nax.plot(freqs_plot.to_value(u.GHz), true_flux_plot.to_value(u.mJy), label=\"True Model\", color=\"black\")\n\n# Add our synthetic data points.\nax.errorbar(\n    frequencies[~censored_mask].to_value(u.GHz),\n    synthetic_flux[~censored_mask].to_value(u.mJy),\n    yerr=noise_fraction * synthetic_flux[~censored_mask].to_value(u.mJy),\n    fmt=\"o\",\n    label=\"Synthetic Data\",\n    color=\"red\",\n)\n# Add censored points\nax.scatter(\n    frequencies[censored_mask].to_value(u.GHz),\n    synthetic_flux[censored_mask].to_value(u.mJy),\n    marker=\"v\",\n    color=\"blue\",\n    label=\"Censored Data\",\n)\n\nax.axhline(flux_floor.to_value(\"mJy\"), color=\"black\", ls=\"--\", label=\"Flux Limit\")\n\nax.set_xlabel(\"Frequency [Hz]\")\nax.set_ylabel(\"Flux Density [mJy]\")\nax.set_xscale(\"log\")\nax.set_yscale(\"log\")\nax.legend()\n\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Inference\nNow that we have our synthetic dataset, we can set up the inference to recover the original parameters.\nWe'll use MCMC for this purpose, which requires us to define a likelihood function and priors for the parameters.\n\nTo start, we'll need to create a data container object to hold our synthetic data. We'll use\na :class:`~astropy.table.Table` object and then feed it into the\n:class:`~data.photometry.RadioPhotometryEpochContainer`.\n\nInside of the data container, we'll put our frequencies, flux densities, flux density errors, and upper limits. We'll\nplace the detections above our ``flux_floor`` and we'll set our upper limits to the cases where the flux density\nplus noise would have fallen below that threshold.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from astropy.table import Table\n\nfrom triceratops.data.photometry import RadioPhotometryEpochContainer\n\n# Create an Astropy Table with the synthetic data. We'll have everything happen at the same\n# epoch in this case (dummy time column), and we'll set the upper limits to NaN since we have detections.\ndata_table = Table()\ndata_table[\"freq\"] = frequencies\ndata_table[\"flux_density\"] = synthetic_flux\ndata_table[\"flux_density_error\"] = noise_fraction * synthetic_flux\ndata_table[\"flux_upper_limit\"] = np.full((frequencies.size,), np.nan) * u.mJy  # No upper limits\n\n# Swap in upper limits where appropriate\ndata_table[\"flux_upper_limit\"][censored_mask] = synthetic_flux[censored_mask]\ndata_table[\"flux_density\"][censored_mask] = np.nan * u.mJy\ndata_table[\"flux_density_error\"][censored_mask] = flux_floor / 3  # dummy error for censored points\n\n\n# Create the RadioPhotometryContainer from the table.\nphotometry_data = RadioPhotometryEpochContainer(data_table)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that we have the data container, we can set up the likelihood function. We'll use the\n:class:`inference.likelihood.base.GaussianLikelihoodXY` for this purpose.\n\nThis likelihood works with single-epoch photometry data and assumes Gaussian errors on the flux densities.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from triceratops.inference.likelihood.base import GaussianLikelihoodXY\n\n# Create the likelihood object.\nlikelihood = GaussianLikelihoodXY(\n    model=sed_model,\n    data=photometry_data,\n)\n\n# Print the current log likelihood value for the true parameters.\nlog_likelihood_true = likelihood.log_likelihood(true_params)\nprint(f\"Log Likelihood at True Parameters: {log_likelihood_true}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we need to define priors for the parameters we want to infer and generate an\ninference problem (:class:`inference.problem.InferenceProblem`). We'll use uniform priors for simplicity.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from triceratops.inference.prior import UniformPrior\nfrom triceratops.inference.problem import InferenceProblem\nfrom triceratops.inference.sampling.mcmc import EmceeSampler\n\n# Generate the inference problem\nproblem = InferenceProblem(\n    likelihood=likelihood,\n)\n\n# Set the priors for the parameters.\nproblem.set_prior(\"norm\", \"uniform\", lower=1e-3 * u.Jy, upper=10.0 * u.Jy)\nproblem.set_prior(\"nu_break\", \"uniform\", lower=1 * u.GHz, upper=50 * u.GHz)\nproblem.set_prior(\"p\", \"uniform\", lower=2.0, upper=5.0)\n\n# Fix the 's' parameter since we don't want to infer it in this example.\nproblem.parameters[\"s\"].initial_value = true_params[\"s\"]\nproblem.parameters[\"s\"].freeze = True\n\n# Create the sampler.\nsampler = EmceeSampler(problem, n_walkers=32, ensemble_kwargs=dict())\n\n# Run MCMC\nresult = sampler.run(10_000, progress=True)\nsamples = result.get_flat_samples(burn=1000, thin=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we can analyze the MCMC results to see how well we recovered the original parameters.\nFrequencies for plotting\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "freqs_plot = np.logspace(8, 11, 200) * u.Hz\n\nfig, ax = plt.subplots(figsize=(10, 6))\n\n# Plot data\nax.errorbar(\n    frequencies.to_value(u.GHz),\n    synthetic_flux.to_value(u.mJy),\n    yerr=noise_fraction * synthetic_flux.to_value(u.mJy),\n    fmt=\"o\",\n    color=\"red\",\n    label=\"Data\",\n)\n\n# Draw a subset of posterior samples\nn_draw = 100\nidx = np.random.choice(samples.shape[0], n_draw, replace=False)\n\nfor i in idx:\n    theta_free = samples[i]\n    params = problem.unpack_free_parameters(theta_free)\n    flux = sed_model.forward_model({\"frequency\": freqs_plot}, params)[\"flux_density\"]\n\n    ax.plot(freqs_plot.to_value(u.GHz), flux.to_value(u.mJy), color=\"C0\", alpha=0.05)\n\n# Plot true model\ntrue_flux_plot = sed_model.forward_model({\"frequency\": freqs_plot}, true_params)[\"flux_density\"]\n\nax.axhline(flux_floor.to_value(\"mJy\"), color=\"black\", ls=\"--\", label=\"Flux Limit\")\n\nax.plot(freqs_plot.to_value(u.GHz), true_flux_plot.to_value(u.mJy), color=\"black\", lw=2, label=\"True Model\")\n\nax.set_xscale(\"log\")\nax.set_yscale(\"log\")\nax.set_xlabel(\"Frequency [GHz]\")\nax.set_ylabel(\"Flux Density [mJy]\")\nax.legend()\n\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It's also always good practice to look at some diagnostic plots to ensure that the MCMC\nchains have converged and that the posterior distributions look reasonable. We'll use the built-in plotting utilities\nin Triceratops for this.\n\nLet's start by looking at the trace plots for the $\\nu_{\\rm brk}$ parameter.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = result.trace_plot(\"nu_break\", burn=1000, thin=5)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's also look at the corner plot for all the parameters to see their posterior distributions and covariances.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = result.corner_plot(burn=1000, thin=5, parameters=[\"norm\", \"nu_break\", \"p\"])\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}